{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966a883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display cells to maximum width \n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "\n",
    "# lets you preint multiple outputs per cell, not just last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263f3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import time\n",
    "from time import sleep\n",
    "import concurrent\n",
    "import multiprocessing\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import pathlib\n",
    "import configparser\n",
    "import sys\n",
    "import urllib\n",
    "import zipfile\n",
    "import csv\n",
    "sys.path.insert(0, '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/pymetamap-master')\n",
    "from pymetamap import MetaMap  # https://github.com/AnthonyMRios/pymetamap/blob/master/pymetamap/SubprocessBackend.py\n",
    "from pandas import ExcelWriter\n",
    "import ast\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import shlex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36ea5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install thefuzz\n",
    "# %pip install levenshtein\n",
    "# %pip install xlsxwriter\n",
    "\n",
    "from thefuzz import fuzz # fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0709cfa-2550-4a44-8525-6b2beb10b46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_seconds_to_hms(seconds):\n",
    "    \"\"\" converts the elapsed time or runtime to hours, min, sec \"\"\"\n",
    "    hours = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bacfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_sort_ratio(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "\n",
    "    try:\n",
    "        return fuzz.token_sort_ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "sort_ratio = np.vectorize(get_token_sort_ratio)\n",
    "\n",
    "def get_token_set_ratio(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "    try:\n",
    "        return fuzz.token_set_ratio(str1, str2)\n",
    "    except:\n",
    "        return None  \n",
    "set_ratio = np.vectorize(get_token_set_ratio)\n",
    "\n",
    "def get_similarity_score(str1, str2):\n",
    "    \"\"\" fuzzy matching explained: https://www.datacamp.com/tutorial/fuzzy-string-python \"\"\"\n",
    "    try:\n",
    "        return fuzz.ratio(str1, str2)\n",
    "    except:\n",
    "        return None\n",
    "sim_score = np.vectorize(get_similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c7e3d8-1c7a-44a2-afe5-6721f7ca2438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_raw_ct_data():\n",
    "    term_program_flag = True\n",
    "    global data_dir\n",
    "    global data_extracted\n",
    "\n",
    "    # get all the links and associated dates of upload into a dict called date_link\n",
    "    url_all = \"https://aact.ctti-clinicaltrials.org/download\"\n",
    "    response = requests.get(url_all)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    body = soup.find_all('option') #Find all\n",
    "    date_link = {}\n",
    "    for el in body:\n",
    "        tags = el.find('a')\n",
    "        try:\n",
    "            zip_name = tags.contents[0].split()[0]\n",
    "            date = zip_name.split(\"_\")[0]\n",
    "            date = dt.datetime.strptime(date, '%Y%m%d').date()\n",
    "            date_link[date] = tags.get('href')\n",
    "        except:\n",
    "            pass\n",
    "    latest_file_date = max(date_link.keys())   # get the date of the latest upload\n",
    "    url = date_link[latest_file_date]   # get the corresponding download link of the latest upload so we can download the raw data\n",
    "    date_string = latest_file_date.strftime(\"%m_%d_%Y\")\n",
    "    data_dir = \"{}/data\".format(pathlib.Path.cwd())\n",
    "    data_extracted = data_dir + \"/{}_extracted\".format(date_string)\n",
    "    data_path = \"{}/{}_pipe-delimited-export.zip\".format(data_dir, date_string)\n",
    "\n",
    "    if not os.path.exists(data_path):   # if folder containing most recent data doesn't exist, download and extract it into data folder\n",
    "\n",
    "        term_program_flag = False   # flag below for terminating program if latest download exists (KG is assumed up to date)\n",
    "        print(\"Attempting download of Clinical Trial data as of {}\".format(date_string))\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(data_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(\"Finished download of zip\")\n",
    "                with zipfile.ZipFile(data_path, 'r') as download:\n",
    "                    print(\"Unzipping data\")\n",
    "                    download.extractall(data_extracted)\n",
    "        except:\n",
    "            print(\"Failed to scrape AACT for download. Please navigate to https://aact.ctti-clinicaltrials.org/download and manually download zip file.\")\n",
    "            print(\"Please store the downloaded zip in the /data directory\")\n",
    "            done = input(\"Type Done when done: \")\n",
    "            if done == \"Done\":\n",
    "                data_dir = \"{}/data\".format(pathlib.Path.cwd())\n",
    "                list_of_files = glob.glob(data_dir + \"/*\") # get all files in directory\n",
    "                try:\n",
    "                    latest_file = max(list_of_files, key=os.path.getctime) # get the most recent file in the directory\n",
    "                    print(\"File found at: \")\n",
    "                    print(latest_file)\n",
    "                    print(\"Please make sure this the correct zip file from AACT\")\n",
    "                    try:\n",
    "                        with zipfile.ZipFile(latest_file, 'r') as download:\n",
    "                            print(\"Unzipping data into\")\n",
    "                            cttime = os.path.getctime(latest_file)\n",
    "                            date_string = dt.datetime.fromtimestamp(cttime).strftime('%m_%d_%Y')\n",
    "                            data_extracted = data_dir + \"/{}_extracted\".format(date_string)\n",
    "                            print(data_extracted)\n",
    "                            download.extractall(data_extracted)\n",
    "                    except:\n",
    "                        print(\"Assuming data is already unzipped\")\n",
    "                except:\n",
    "                    print(\"Unable to download and extract Clincal Trial data.\")\n",
    "                    print(\"Cannot find pipe-delimited zip in /data folder.\")\n",
    "    else:\n",
    "        print(\"KG is already up to date.\")\n",
    "\n",
    "    return {\"term_program_flag\": term_program_flag, \"data_extracted_path\": data_extracted, \"date_string\": date_string}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bccd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_ct_data(flag_and_path, subset_size):\n",
    "    if flag_and_path[\"term_program_flag\"]:\n",
    "        print(\"Exiting program. Assuming KG has already been constructed from most recent data dump from AACT.\")\n",
    "        exit()\n",
    "    else:\n",
    "        data_extracted = flag_and_path[\"data_extracted_path\"]\n",
    "        \n",
    "        # read in pipe-delimited files \n",
    "        conditions_df = pd.read_csv(data_extracted + '/conditions.txt', sep='|', index_col=False, header=0)\n",
    "        interventions_df = pd.read_csv(data_extracted + '/interventions.txt', sep='|', index_col=False, header=0)\n",
    "        alternate_interventions_df = pd.read_csv(data_extracted + '/intervention_other_names.txt', sep='|', index_col=False, header=0)\n",
    "\n",
    "        if subset_size:   # if a subset size is given, we are running this script on a small subset of the dataset\n",
    "            conditions_df = conditions_df.sample(n=subset_size)\n",
    "            interventions_df = interventions_df.sample(n=subset_size)\n",
    "            alternate_interventions_df = alternate_interventions_df.sample(n=subset_size)\n",
    "\n",
    "    return {\"conditions\": conditions_df, \"interventions\": interventions_df, \"interventions_alts\": alternate_interventions_df}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f277771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_ascii_er(text):\n",
    "    non_ascii = \"[^\\x00-\\x7F]\"\n",
    "    pattern = re.compile(r\"[^\\x00-\\x7F]\")\n",
    "    non_ascii_text = re.sub(pattern, ' ', text)\n",
    "    return non_ascii_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2877eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_metamap_servers(metamap_dirs):\n",
    "    global metamap_pos_server_dir\n",
    "    global metamap_wsd_server_dir\n",
    "    metamap_pos_server_dir = 'bin/skrmedpostctl' # Part of speech tagger\n",
    "    metamap_wsd_server_dir = 'bin/wsdserverctl' # Word sense disambiguation \n",
    "    \n",
    "    metamap_executable_path_pos = os.path.join(metamap_dirs['metamap_base_dir'], metamap_pos_server_dir)\n",
    "    metamap_executable_path_wsd = os.path.join(metamap_dirs['metamap_base_dir'], metamap_wsd_server_dir)\n",
    "    command_pos = [metamap_executable_path_pos, 'start']\n",
    "    command_wsd = [metamap_executable_path_wsd, 'start']\n",
    "\n",
    "    # Start servers, with open portion redirects output of metamap server printing output to NULL\n",
    "    with open(os.devnull, \"w\") as fnull:\n",
    "        result_post = subprocess.call(command_pos, stdout = fnull, stderr = fnull)\n",
    "        result_wsd = subprocess.call(command_wsd, stdout = fnull, stderr = fnull)\n",
    "    sleep(5)\n",
    "\n",
    "def stop_metamap_servers(metamap_dirs):\n",
    "    metamap_executable_path_pos = os.path.join(metamap_dirs['metamap_base_dir'], metamap_pos_server_dir)\n",
    "    metamap_executable_path_wsd = os.path.join(metamap_dirs['metamap_base_dir'], metamap_wsd_server_dir)\n",
    "    command_pos = [metamap_executable_path_pos, 'stop']\n",
    "    command_wsd = [metamap_executable_path_wsd, 'stop']\n",
    "    \n",
    "    # Stop servers, with open portion redirects output of metamap server printing output to NULL\n",
    "    with open(os.devnull, \"w\") as fnull:\n",
    "        result_post = subprocess.call(command_pos, stdout = fnull, stderr = fnull)\n",
    "        result_wsd = subprocess.call(command_wsd, stdout = fnull, stderr = fnull)\n",
    "    sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6b59f-1119-47fc-aba6-c98de552f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming dirs['mm_base_dir'], mm_pos_server_dir, and other variables are defined\n",
    "# executable_path = os.path.join(dirs['mm_base_dir'], mm_pos_server_dir)\n",
    "# command = [executable_path, 'start']\n",
    "\n",
    "# with open(os.devnull, 'w') as fnull:\n",
    "#     result = subprocess.call(command, stdout=fnull, stderr=fnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25ddab-7e22-4b81-8e1b-a1a1cae1e819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metamap_base_dir = '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/public_mm/' # for running on local\n",
    "# metamap_bin_dir = 'bin/metamap18'\n",
    "\n",
    "# metamap_pos_server_dir = 'bin/skrmedpostctl' # Part of speech tagger\n",
    "# metamap_wsd_server_dir = 'bin/wsdserverctl' # Word sense disambiguation \n",
    "\n",
    "# # os.system(metamap_base_dir + metamap_pos_server_dir + ' start') # Part of speech tagger\n",
    "# # os.system(metamap_base_dir + metamap_wsd_server_dir + ' start') # Word sense disambiguation \n",
    "\n",
    "# os.system(metamap_base_dir + metamap_pos_server_dir + ' stop') # Part of speech tagger\n",
    "# os.system(metamap_base_dir + metamap_wsd_server_dir + ' stop') # Word sense disambiguation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e63785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_os():\n",
    "    if \"linux\" in sys.platform:\n",
    "        print(\"Linux platform detected\")\n",
    "        metamap_base_dir = \"{}/metamap/\".format(pathlib.Path.cwd().parents[0])\n",
    "        metamap_bin_dir = 'bin/metamap20'\n",
    "    else:\n",
    "        metamap_base_dir = '/Volumes/TOSHIBA_EXT/ISB/clinical_trials/public_mm/' # for running on local\n",
    "        metamap_bin_dir = 'bin/metamap18'\n",
    "        \n",
    "    return {\"metamap_base_dir\":metamap_base_dir, \"metamap_bin_dir\":metamap_bin_dir}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ea402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metamap(input_term, params, mm, cond_or_inter, csv_writer):\n",
    "    from_metamap = []\n",
    "    if params.get(\"exclude_sts\") is None: # exclude_sts is used for Interventions. restrict_to_sts is used for Conditions. So, the logic is, if we're mapping Conditions, execute \"if\" part of code. If we're mapping Interventions, execute \"else\" part of code\n",
    "        try:\n",
    "            concepts,error = mm.extract_concepts([input_term],\n",
    "                                                 restrict_to_sts = params[\"restrict_to_sts\"],\n",
    "                                                 term_processing = params[\"term_processing\"],\n",
    "                                                 ignore_word_order = params[\"ignore_word_order\"],\n",
    "                                                 strict_model = params[\"strict_model\"],\n",
    "                                                )\n",
    "            for concept in concepts:\n",
    "                concept_info = []\n",
    "                concept = concept._asdict()\n",
    "                concept_info.extend([cond_or_inter,input_term])\n",
    "                concept_info.extend([concept.get(k) for k in ['preferred_name', 'cui', 'score', 'semtypes']])\n",
    "                from_metamap.append(concept_info)\n",
    "        except:\n",
    "            from_metamap.extend([input_term, None, None, None, None, None, None])\n",
    "    else:\n",
    "        try:\n",
    "            concepts,error = mm.extract_concepts([input_term],\n",
    "                                                 exclude_sts = params[\"exclude_sts\"],\n",
    "                                                 term_processing = params[\"term_processing\"],\n",
    "                                                 ignore_word_order = params[\"ignore_word_order\"],\n",
    "                                                 strict_model = params[\"strict_model\"],\n",
    "                                                )\n",
    "            for concept in concepts:\n",
    "                concept_info = []\n",
    "                concept = concept._asdict()\n",
    "                concept_info.extend([cond_or_inter,input_term])\n",
    "                concept_info.extend([concept.get(k) for k in ['preferred_name', 'cui', 'score', 'semtypes']])\n",
    "                from_metamap.append(concept_info)\n",
    "        except:\n",
    "            from_metamap.extend([input_term, None, None, None, None, None, None])\n",
    "        \n",
    "    for result in from_metamap:\n",
    "        # print(result)\n",
    "        csv_writer.writerow(result)\n",
    "    return from_metamap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a937acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_metamap(term_list, params, cond_or_inter, flag_and_path, csv_writer):\n",
    "    LENGTH = len(term_list)  # Number of iterations required to fill progress bar (pbar)\n",
    "    pbar = tqdm(total=LENGTH, desc=\"% {}s mapped\".format(cond_or_inter), position=0, leave=True, mininterval = LENGTH/10)  # Init progress bar\n",
    "\n",
    "    start_metamap_servers(metamap_dirs) # start the MetaMap servers\n",
    "    mm = MetaMap.get_instance(metamap_dirs[\"metamap_base_dir\"] + metamap_dirs[\"metamap_bin_dir\"])\n",
    "    with concurrent.futures.ThreadPoolExecutor((multiprocessing.cpu_count()*2) - 1) as executor:\n",
    "        futures = [executor.submit(run_metamap, term, params, mm, cond_or_inter, csv_writer) for term in term_list]\n",
    "        for _ in concurrent.futures.as_completed(futures):\n",
    "            pbar.update(n=1)  # Increments counter\n",
    "    stop_metamap_servers(metamap_dirs) # stop the MetaMap servers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8f2ff-08d5-4543-8acc-8995175749b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# command = [\"executable\", \"argument_1\", \"argument_2\"]\n",
    "\n",
    "# with open(os.devnull, \"w\") as fnull:\n",
    "#     result = subprocess.call(command, stdout = fnull, stderr = fnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef9aa-e6e5-4cc2-93af-b1130e3ea56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# #   ... snip.....\n",
    "\n",
    "# LENGTH = len(lista_hosts)  # Number of iterations required to fill pbar\n",
    "# pbar = tqdm(total=LENGTH, desc='consulta_comando', position=0, leave=True)  # Init pbar\n",
    "# with ThreadPoolExecutor(200) as executor:\n",
    "#     futures = [executor.submit(comando_remoto.comando_remoto_hosts,\n",
    "#                                add_dns_cc.add_dns_concesion(host),\n",
    "#                                comando, res_versiones, user, clave_rsa,\n",
    "#                                passwd) for host in lista_hosts]\n",
    "#     for _ in as_completed(futures):\n",
    "#         pbar.update(n=1)  # Increments counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a21d47",
   "metadata": {},
   "source": [
    "# USE METAMAP LOCAL TO MAP REMAINING TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f37ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_list_to_mm(df_dict, flag_and_path):\n",
    "        \n",
    "    metamap_version = [int(s) for s in re.findall(r'\\d+', metamap_dirs.get('metamap_bin_dir'))] # get MetaMap version being run \n",
    "    # some input terms have () with additional text, like an abbreviation, in them. split them out to facilitate better mapping using these regex patterns that we use to find substrings inside and outside ()\n",
    "    pattern_outside = r'(?<=\\().+?(?=\\))|([^(]+)'\n",
    "    pattern_inside = r'\\(([^)]+)\\)'\n",
    "    relevant_date = flag_and_path[\"date_string\"]   # get date of bulk download of clinical trial data\n",
    "    deasciier = np.vectorize(de_ascii_er) # vectorize function\n",
    "\n",
    "    # -------    CONDITIONS    ------- #\n",
    "    print(\"Using UMLS MetaMap to get mappings for CONDITIONS. MetaMap returns mappings, CUIs, and semantic type of mapping.\")\n",
    "    conditions = df_dict[\"conditions\"][['id', 'nct_id', 'downcase_name']]\n",
    "    conditions = conditions.copy()\n",
    "    conditions.rename(columns = {'downcase_name':'orig_con'}, inplace = True)\n",
    "\n",
    "    if metamap_version[0] >= 20:\n",
    "        matches_outside = conditions['orig_con'].str.extract(pattern_outside)\n",
    "        conditions['orig_con_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = conditions['orig_con'].str.extract(pattern_inside)\n",
    "        conditions['orig_con_inside'] = matches_inside[0].fillna('')\n",
    "\n",
    "    else:\n",
    "        conditions['deascii_con'] = deasciier(conditions['orig_con'])\n",
    "        matches_outside = conditions['deascii_con'].str.extract(pattern_outside)\n",
    "        conditions['deascii_con_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = conditions['deascii_con'].str.extract(pattern_inside)\n",
    "        conditions['deascii_con_inside'] = matches_inside[0].fillna('')\n",
    "    \n",
    "#     see MetaMap Usage instructions: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/MM_2016_Usage.pdf\n",
    "#     condition_args = ['--sldi -I -C -J acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf -z -i -f']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    condition_semantic_type_restriction = ['acab,anab,cgab,comd,dsyn,inpo,mobd,neop,patf,clna,fndg']  # see https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemanticTypes_2018AB.txt for semantic types (\"acab,anab,etc.\")\n",
    "    params = {\"restrict_to_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "    \n",
    "    # prep output file of Metamap results\n",
    "    filename = f\"{relevant_date}_metamap_output.tsv\"\n",
    "    metamap_output = open(filename, 'w+', newline='')\n",
    "    col_names = ['term_type', 'clin_trial_term','metamap_preferred_name', 'metamap_cui', 'metamap_score', 'metamap_semantic_type']\n",
    "    csv_writer = csv.writer(metamap_output, delimiter='\\t')\n",
    "    csv_writer.writerow(col_names)\n",
    "    \n",
    "    if metamap_version[0] >= 20:\n",
    "        print(\"MetaMap version >= 2020, conduct mapping on original terms\")\n",
    "        orig_cons = conditions.orig_con.unique().tolist()\n",
    "        orig_cons = list(filter(None, orig_cons))\n",
    "        orig_cons = [str(i) for i in orig_cons]\n",
    "        parallelize_metamap(orig_con, params, \"condition\", flag_and_path, csv_writer)\n",
    "    else:\n",
    "        print(\"MetaMap version < 2020, conduct mapping on terms after removing ascii characters\")\n",
    "        deascii_cons = conditions.deascii_con.unique().tolist()\n",
    "        deascii_cons = list(filter(None, deascii_cons))\n",
    "        deascii_cons = [str(i) for i in deascii_cons]\n",
    "        parallelize_metamap(deascii_cons, params, \"condition\", flag_and_path, csv_writer)\n",
    "        \n",
    "        \"\"\" If the substring that was either outside or inside the () is identical to the term from which it came from, or actually any of the columns have the same value, put None in that cell/put None where that term is duplicated \"\"\"    \n",
    "    # Iterate through each column in the DataFrame\n",
    "    for col1 in conditions.columns:\n",
    "        for col2 in conditions.columns:\n",
    "            # Skip comparing a column with itself\n",
    "            if col1 != col2:\n",
    "                # Check if the values in col2 are duplicates of col1\n",
    "                conditions[col2] = conditions.apply(lambda row: row[col2] if row[col2] != row[col1] else None, axis=1)\n",
    "    # Drop duplicate columns (keeping the first instance)\n",
    "    conditions = conditions.T.drop_duplicates().T\n",
    "\n",
    "    conditions.to_csv('{}_conditions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output interventions to TSV\n",
    "    \n",
    "    # -------    INTERVENTIONS    ------- #\n",
    "    print(\"Using UMLS MetaMap to get mappings for INTERVENTIONS. MetaMap returns mappings, CUIs, and semantic type of mapping.\")\n",
    "    \n",
    "    \"\"\" Interventions requires unique handling. Another table gives possible alternate names for the interventions in addition to the \"original\" names. \n",
    "        We may map on the alternate names column\n",
    "        We take the interventions, take the ascii and deasciied versions of them,\n",
    "        and split substrings in parentheses out of them. We perform MetaMapping on the\n",
    "        original term or the deasciied term dependinging on what operating system we\n",
    "        are on. If the mapped term passes the fuzzy scoring thesholds for any of the\n",
    "        terms (original, deasciied, original inside the parentheses, deasciied inside\n",
    "        the parentheses, original outside the parentheses, deasciied outside the\n",
    "        parentheses\"\"\" \n",
    "\n",
    "    interventions_df = df_dict[\"interventions\"]\n",
    "    interventions_df['orig_downcase_name'] = interventions_df['name'].str.lower()\n",
    "    interventions_alts = df_dict[\"interventions_alts\"]\n",
    "    interventions_alts['alt_downcase_name'] = interventions_alts['name'].str.lower()\n",
    "    \n",
    "    orig_ints = interventions_df[\"orig_downcase_name\"]\n",
    "    orig_ints = list(orig_ints.unique())\n",
    "    orig_ints = list(filter(None, orig_ints))\n",
    "    alt_ints = interventions_alts[\"alt_downcase_name\"]\n",
    "    alt_ints = list(alt_ints.unique())\n",
    "    alt_ints = list(filter(None, alt_ints))\n",
    "\n",
    "    params = {\"exclude_sts\":condition_semantic_type_restriction, \"term_processing\":True, \"ignore_word_order\":True, \"strict_model\":False} # strict_model and relaxed_model are presumably opposites? relaxed_model = True is what I want, but that option appears to be broken in Pymetamap (returns no results when used). Using strict_model = False instead...\n",
    "    \"\"\" Send the prepared interventions to MetaMap now. If we are on OSX, we have to use MetaMap 2018, which requires deasciied terms. If we are on Linux, we can use MetaMap 2020, which does not require such preprocessing \"\"\"\n",
    "    if metamap_version[0] < 20:\n",
    "        deasciier = np.vectorize(de_ascii_er) # vectorize function\n",
    "        #  -------   original interventions  -------- #\n",
    "        orig_ints = [str(i) for i in orig_ints]\n",
    "        orig_ints = deasciier(orig_ints) # perform deascii-ing on original intervention names\n",
    "        orig_ints = list(orig_ints)\n",
    "        print(\"MetaMap version < 2020, conduct mapping on original interventions after removing ascii characters\")\n",
    "        parallelize_metamap(orig_ints, params, \"intervention\", flag_and_path, csv_writer)\n",
    "        #  ---------   alternate interventions ------- #\n",
    "        alt_ints = [str(i) for i in alt_ints]\n",
    "        alt_ints = deasciier(alt_ints) # perform deascii-ing on alternate intervention names\n",
    "        alt_ints = list(alt_ints)\n",
    "        parallelize_metamap(alt_ints, params, \"alternate_intervention\", flag_and_path, csv_writer)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #  -------   original interventions  -------- #\n",
    "        print(\"MetaMap version >= 2020, conduct mapping on original interventions\")\n",
    "        parallelize_metamap(orig_ints, params, \"intervention\", flag_and_path, csv_writer)\n",
    "        #  ---------   alternate interventions ------- #\n",
    "        print(\"MetaMap version >= 2020, conduct mapping on alternate interventions\")\n",
    "        parallelize_metamap(alt_ints, params, \"alternate_intervention\", flag_and_path, csv_writer)\n",
    "\n",
    "    interventions_all = pd.merge(interventions_df[[\"id\", \"nct_id\", \"intervention_type\", \"orig_downcase_name\", \"description\"]], interventions_alts[[\"nct_id\", \"intervention_id\", \"alt_downcase_name\"]], how='left', left_on=['id'], right_on = ['intervention_id'])\n",
    "    interventions_all = interventions_all.astype(str)\n",
    "    interventions_all = interventions_all.drop('nct_id_y', axis=1) # drop the redundant column now\n",
    "    interventions_all.rename(columns = {'nct_id_x':'nct_id'}, inplace = True)\n",
    "\n",
    "    interventions_all = interventions_all.sort_values(by='nct_id', ascending=False, na_position='last')\n",
    "    interventions_all = interventions_all.drop('intervention_id', axis=1) # drop the redundant column now\n",
    "    interventions_all.rename(columns = {'id':'intervention_id', 'orig_downcase_name':'orig_int', 'alt_downcase_name':'alt_int'}, inplace = True)\n",
    "\n",
    "    if metamap_version[0] >= 20:\n",
    "        matches_outside = interventions_all['orig_int'].str.extract(pattern_outside)\n",
    "        interventions_all['orig_int_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = interventions_all['orig_int'].str.extract(pattern_inside)\n",
    "        interventions_all['orig_int_inside'] = matches_inside[0].fillna('')\n",
    "\n",
    "        matches_outside = interventions_all['alt_int'].str.extract(pattern_outside)\n",
    "        interventions_all['alt_int_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = interventions_all['alt_in'].str.extract(pattern_inside)\n",
    "        interventions_all['alt_int_inside'] = matches_inside[0].fillna('')\n",
    "    else:\n",
    "\n",
    "        interventions_all['deascii_orig_int'] = deasciier(interventions_all['orig_int'])\n",
    "        interventions_all['deascii_alt_int'] = deasciier(interventions_all['alt_int'])\n",
    "\n",
    "        matches_outside = interventions_all['deascii_orig_int'].str.extract(pattern_outside)\n",
    "        interventions_all['deascii_orig_int_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = interventions_all['deascii_orig_int'].str.extract(pattern_inside)\n",
    "        interventions_all['deascii_orig_int_inside'] = matches_inside[0].fillna('')\n",
    "\n",
    "        matches_outside = interventions_all['deascii_alt_int'].str.extract(pattern_outside)\n",
    "        interventions_all['deascii_alt_int_outside'] = matches_outside[0].fillna('')\n",
    "        matches_inside = interventions_all['deascii_alt_int'].str.extract(pattern_inside)\n",
    "        interventions_all['deascii_alt_name_inside'] = matches_inside[0].fillna('')\n",
    "\n",
    "    \"\"\" I don't want to perform mapping on strings < 4 char in length; these are ambiguous and it's hard to make a call what that concept should be \"\"\"\n",
    "    \"\"\" Get character counts of all the columns to evaluate \"\"\"    \n",
    "    for col in interventions_all.columns: # get the char counts of each column\n",
    "        char_count_col_name = col + '_char_count'\n",
    "        interventions_all[char_count_col_name] = interventions_all[col].str.len()\n",
    "\n",
    "    \"\"\" If char_count < 4, replace the string in the corresponding column with None so that we don't use it for comparison \"\"\"    \n",
    "    for col in interventions_all.columns[interventions_all.columns.str.contains(\"char_count\")]:\n",
    "        for index, value in interventions_all[col].items():\n",
    "            if value < 4:\n",
    "                # Find the column with the most similar name without \"char_count\" substring\n",
    "                most_similar_col = interventions_all.columns[interventions_all.columns.str.replace(\"_char_count\", \"\") == col.replace(\"_char_count\", \"\")].values[0]\n",
    "                # Update the value in the most similar column\n",
    "                interventions_all.at[index, most_similar_col] = None\n",
    "        interventions_all = interventions_all.drop(col, axis=1) # drop the count columns now  \n",
    "        \n",
    "    \"\"\" If the substring that was either outside or inside the () is identical to the term from which it came from, or actually any of the columns have the same value, put None in that cell/put None where that term is duplicated \"\"\"    \n",
    "    # Iterate through each column in the DataFrame\n",
    "    for col1 in interventions_all.columns:\n",
    "        for col2 in interventions_all.columns:\n",
    "            # Skip comparing a column with itself\n",
    "            if col1 != col2:\n",
    "                # Check if the values in col2 are duplicates of col1\n",
    "                interventions_all[col2] = interventions_all.apply(lambda row: row[col2] if row[col2] != row[col1] else None, axis=1)\n",
    "    # Drop duplicate columns (keeping the first instance)\n",
    "    interventions_all = interventions_all.T.drop_duplicates().T\n",
    "\n",
    "\n",
    "    interventions_all.to_csv('{}_interventions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output interventions to TSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42025af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_trial(df_dict, flag_and_path):\n",
    "    # send mappings to interventions and conditions, group CUIs that correspond to input condition or intervention\n",
    "    \n",
    "    print(\"Mapping UMLS CURIEs and names back to clinical trials\")\n",
    "    relevant_date = flag_and_path[\"date_string\"]   # get date of bulk download of clinical trial data\n",
    "    metamap_version = [int(s) for s in re.findall(r'\\d+', metamap_dirs.get('metamap_bin_dir'))] # get MetaMap version being run \n",
    "\n",
    "    metamap_input = \"{}_metamap_output.tsv\".format(relevant_date)\n",
    "    metamapped = pd.read_csv(metamap_input, sep='\\t', index_col=False, header=0)\n",
    "\n",
    "    # get the full names of the semantic types so we know what we're looking at\n",
    "    metamap_semantic_types = pd.read_csv(\"MetaMap_SemanticTypes_2018AB.txt\")\n",
    "    metamapped['metamap_semantic_type'] = metamapped['metamap_semantic_type'].str.replace(r'\\[|\\]', '', regex=True)\n",
    "    sem_type_col_names = [\"abbv\", \"group\", \"semantic_type_full\"]\n",
    "    metamap_semantic_types = pd.read_csv(\"MetaMap_SemanticTypes_2018AB.txt\", sep=\"|\", index_col=False, header=None, names=sem_type_col_names)\n",
    "    sem_type_dict = dict(zip(metamap_semantic_types['abbv'], metamap_semantic_types['semantic_type_full'])) # make a dict of semantic type abbv and full name\n",
    "    # Handle NaN (None) values in metamap_semantic_type column\n",
    "    metamapped['metamap_semantic_type'] = metamapped['metamap_semantic_type'].apply(lambda x: x.split(',') if isinstance(x, str) else np.nan)\n",
    "    # map semantic type abbreviations to the full name of the semantic type\n",
    "    metamapped['metamap_semantic_type'] = metamapped['metamap_semantic_type'].apply(lambda x: '|'.join([sem_type_dict[term] if term in sem_type_dict else term for term in x]) if isinstance(x, list) else x)\n",
    "\n",
    "    metamapped['metamap_preferred_name'] = metamapped['metamap_preferred_name'].str.lower()\n",
    "    metamapped = metamapped.dropna(axis=0)\n",
    "    metamapped = metamapped[[\"term_type\", \"clin_trial_term\", \"metamap_cui\",\"metamap_preferred_name\", \"metamap_semantic_type\"]]\n",
    "\n",
    "    metamapped[\"metamap_term_info\"] = metamapped[[\"metamap_cui\", \"metamap_preferred_name\", \"metamap_semantic_type\"]].values.tolist() \n",
    "    metamapped.drop([\"metamap_cui\", \"metamap_preferred_name\", \"metamap_semantic_type\"], axis = 1, inplace = True)\n",
    "    metamapped = metamapped.groupby(['term_type', 'clin_trial_term'])['metamap_term_info'].agg(list).reset_index()\n",
    "\n",
    "    conditions = '{}_conditions.tsv'.format(relevant_date)\n",
    "    conditions = pd.read_csv(conditions, sep='\\t', index_col=False, header=0)\n",
    "    interventions = '{}_interventions.tsv'.format(relevant_date)\n",
    "    interventions = pd.read_csv(interventions, sep='\\t', index_col=False, header=0)\n",
    "\n",
    "    metamapped_con = metamapped.loc[metamapped['term_type'] == \"condition\"]\n",
    "    metamapped_int = metamapped.loc[(metamapped['term_type'] == \"intervention\") | (metamapped['term_type'] == \"alternate_intervention\")]\n",
    "\n",
    "    mapper_con = dict(zip(metamapped_con['clin_trial_term'], metamapped_con['metamap_term_info'])) # make a dict to map conditions\n",
    "    mapper_int = dict(zip(metamapped_int['clin_trial_term'], metamapped_int['metamap_term_info'])) # make a dict to map interventions\n",
    "\n",
    "#     cols_to_check = [ele for ele in conditions.columns if(ele not in ['id', 'nct_id', 'condition_id'])]\n",
    "    cols_to_check = [ele for ele in conditions.columns if any([substr in ele for substr in ['_con']])]\n",
    "\n",
    "    conditions[\"curie_info\"] = None\n",
    "\n",
    "    for index, row in conditions.iterrows():\n",
    "        for col_name in cols_to_check:\n",
    "            value = row[col_name]\n",
    "            if value in mapper_con:\n",
    "                curie_info = mapper_con[value]\n",
    "                conditions.at[index, \"curie_info\"] = curie_info    \n",
    "                \n",
    "    conditions.to_csv('{}_conditions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output conditions to TSV\n",
    "\n",
    "#     cols_to_check = [ele for ele in interventions.columns if(ele not in ['id', 'nct_id', 'intervention_id', 'intervention_type', 'description'])]\n",
    "    cols_to_check = [ele for ele in interventions.columns if any([substr in ele for substr in ['_int']])]\n",
    "\n",
    "    interventions[\"curie_info\"] = None\n",
    "\n",
    "    for index, row in interventions.iterrows():\n",
    "        for col_name in cols_to_check:\n",
    "            value = row[col_name]\n",
    "            if value in mapper_int:\n",
    "                curie_info = mapper_int[value]\n",
    "                interventions.at[index, \"curie_info\"] = curie_info\n",
    "    \n",
    "    interventions.to_csv('{}_interventions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output interventions to TSV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcfdd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mappings(flag_and_path):\n",
    "    \n",
    "    print(\"Scoring mappings\")\n",
    "    relevant_date = flag_and_path[\"date_string\"]   # get date of bulk download of clinical trial data\n",
    "    \n",
    "    #   -- --- --   CONDITIONS   -- --- -- #\n",
    "    conditions = \"{}_conditions.tsv\".format(relevant_date)\n",
    "    conditions = pd.read_csv(conditions, sep='\\t', index_col=False, header=0)\n",
    "    cols_to_check = [ele for ele in conditions.columns if any([substr in ele for substr in ['_con']])]\n",
    "    conditions = conditions.where(pd.notnull(conditions), None)\n",
    "\n",
    "    for index, row in conditions.iterrows():\n",
    "        curies_sublists_scored = []\n",
    "        for col_name in cols_to_check:\n",
    "            value = row[col_name]\n",
    "            curie_info = row[\"curie_info\"]\n",
    "            if None not in [value, curie_info]:\n",
    "                curie_sublists = ast.literal_eval(curie_info)\n",
    "                for sublist in curie_sublists:\n",
    "                    sublist.append(f'sort_ratio: {get_token_sort_ratio(value, sublist[1])}')\n",
    "                    sublist.append(f'similarity_score: {get_similarity_score(value, sublist[1])}')\n",
    "                    curies_sublists_scored.append(sublist)\n",
    "        conditions.at[index, \"curie_info\"] = curies_sublists_scored\n",
    "    conditions.to_csv('{}_conditions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output to TSV\n",
    "\n",
    "    #   -- --- --   INTERVENTIONS   -- --- -- #\n",
    "    \n",
    "    interventions = \"{}_interventions.tsv\".format(relevant_date)\n",
    "    interventions = pd.read_csv(interventions, sep='\\t', index_col=False, header=0)\n",
    "    cols_to_check = [ele for ele in interventions.columns if any([substr in ele for substr in ['_int']])]\n",
    "    interventions = interventions.where(pd.notnull(interventions), None)\n",
    "\n",
    "    for index, row in interventions.iterrows():\n",
    "        curies_sublists_scored = []\n",
    "        for col_name in cols_to_check:\n",
    "            value = row[col_name]\n",
    "            curie_info = row[\"curie_info\"]\n",
    "            if None not in [value, curie_info]:\n",
    "                curie_sublists = ast.literal_eval(curie_info)\n",
    "                for sublist in curie_sublists:\n",
    "                    sublist.append(f'sort_ratio: {get_token_sort_ratio(value, sublist[1])}')\n",
    "                    sublist.append(f'similarity_score: {get_similarity_score(value, sublist[1])}')\n",
    "                    curies_sublists_scored.append(sublist)\n",
    "\n",
    "        interventions.at[index, \"curie_info\"] = curies_sublists_scored\n",
    "    interventions.to_csv('{}_interventions.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output interventions to TSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e75aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_select_curies(flag_and_path):\n",
    "    print(\"Auto-selecting high scoring CURIEs\")\n",
    "    relevant_date = flag_and_path[\"date_string\"]   # get date of bulk download of clinical trial data\n",
    "    \n",
    "    def filter_and_select_sublist(sublists):  # function to find the highest score of a CURIE, and pick that curie if it's greater than threshold of 88\n",
    "        if sublists is None or len(sublists) == 0:\n",
    "            return None\n",
    "\n",
    "        high_score = -1\n",
    "        selected_sublist = None\n",
    "\n",
    "        sublists = ast.literal_eval(sublists)\n",
    "        for sublist in sublists:\n",
    "\n",
    "            if len(sublist) >= 4:\n",
    "                sort_ratio = int(sublist[3].split(\": \")[1])\n",
    "                sim_score = int(sublist[4].split(\": \")[1])\n",
    "                max_score = max(sort_ratio, sim_score)\n",
    "                if max_score > 88: \n",
    "                    if max_score > high_score:\n",
    "                        high_score = max_score\n",
    "                        selected_sublist = sublist\n",
    "        return selected_sublist\n",
    "\n",
    "    #   -----   -----    -----   -----   CONDITIONS   -----   -----    -----   -----  #\n",
    "\n",
    "    conditions = \"{}_conditions.tsv\".format(relevant_date)\n",
    "    conditions = pd.read_csv(conditions, sep='\\t', index_col=False, header=0)\n",
    "    \"\"\"  Create an output TSV of CURIEs that are auto-selected based on passing the threshold of scoring > 88  \"\"\"\n",
    "    conditions['auto_selected_curie'] = conditions['curie_info'].apply(filter_and_select_sublist)  # select CURIE that scores highest using filter_and_select_sublist function = auto-select\n",
    "    auto_selected_conditions = conditions[conditions[['auto_selected_curie']].notnull().all(1)]   # get the rows where a CURIE has been auto-selected\n",
    "    auto_selected_conditions = auto_selected_conditions[[\"id\", \"nct_id\", \"orig_con\", \"curie_info\", \"auto_selected_curie\"]]  # subset dataframe\n",
    "    auto_selected_conditions.to_csv('{}_conditions_auto_selected.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output to TSV\n",
    "\n",
    "    conditions_manual_review = conditions[conditions[\"auto_selected_curie\"].isna()]   # select rows where no CURIE was auto-selected\n",
    "    conditions_manual_review = conditions_manual_review[[\"orig_con\", \"curie_info\"]]  # subset\n",
    "\n",
    "    \"\"\"  Create an output TSV of possible CURIEs available for each term that was not auto-selected  \"\"\"\n",
    "    conditions_manual_review['curie_info'] = conditions_manual_review['curie_info'].apply(ast.literal_eval)   # in order to multi-index, we have to group-by the original input term. To do this, first convert the column to list of lists\n",
    "    conditions_manual_review = conditions_manual_review.explode('curie_info')  # explode that column so every sublist is on a separate row\n",
    "    conditions_manual_review['curie_info'] = conditions_manual_review['curie_info'].apply(lambda x: x[:3] if isinstance(x, list) else None)   # remove the scores (sort_ratio and similarity score) from the list, don't need them and they compromise readability of manual outputs \n",
    "    conditions_manual_review['curie_info'] = conditions_manual_review['curie_info'].apply(lambda x: ', '.join(x) if isinstance(x, list) else None)  # Multindexing does not work on lists, so remove the CURIE information out of the list to enable this\n",
    "\n",
    "    conditions_manual_review['temp'] = \"temp\"   # create a temp column to facilitate multi-indexing\n",
    "    conditions_manual_review.set_index([\"orig_con\", 'curie_info'], inplace=True)   # create index\n",
    "    conditions_manual_review.drop([\"temp\"], axis = 1, inplace = True)   # drop the temp column\n",
    "    conditions_manual_review['manually_selected_CURIE'] = None # make a column \n",
    "\n",
    "    conditions_manual_review.to_excel('{}_conditions_manual_review.xlsx'.format(relevant_date), engine='xlsxwriter', index=True)\n",
    "\n",
    "    #   -----   -----    -----   -----   INTERVENTIONS   -----   -----    -----   -----  #\n",
    "    interventions = \"{}_interventions.tsv\".format(relevant_date)\n",
    "    interventions = pd.read_csv(interventions, sep='\\t', index_col=False, header=0)\n",
    "    \"\"\"  Create an output TSV of CURIEs that are auto-selected based on passing the threshold of scoring > 88  \"\"\"\n",
    "    interventions['auto_selected_curie'] = interventions['curie_info'].apply(filter_and_select_sublist)\n",
    "    auto_selected_interventions = interventions[interventions[['auto_selected_curie']].notnull().all(1)]\n",
    "    auto_selected_interventions = auto_selected_interventions[[\"intervention_id\", \"nct_id\", \"intervention_type\", \"orig_int\", \"description\", \"curie_info\", \"auto_selected_curie\"]]\n",
    "    auto_selected_interventions.to_csv('{}_interventions_auto_selected.tsv'.format(relevant_date), sep=\"\\t\", index=False, header=True) # output interventions to TSV, avoid storing in memory\n",
    "\n",
    "    interventions_manual_review = interventions[interventions[\"auto_selected_curie\"].isna()]\n",
    "    interventions_manual_review = interventions_manual_review[[\"intervention_type\", \"orig_int\", \"description\", \"curie_info\"]]\n",
    "\n",
    "    \"\"\"  Create an output TSV of possible CURIEs available for each term that was not auto-selected  \"\"\"\n",
    "    interventions_manual_review['curie_info'] = interventions_manual_review['curie_info'].apply(ast.literal_eval)\n",
    "    interventions_manual_review = interventions_manual_review.explode('curie_info')\n",
    "    interventions_manual_review['curie_info'] = interventions_manual_review['curie_info'].apply(lambda x: x[:3] if isinstance(x, list) else None)   # remove the scores (sort_ratio and similarity score) from the list, don't need them and they compromise readability of manual outputs \n",
    "    interventions_manual_review['curie_info'] = interventions_manual_review['curie_info'].apply(lambda x: ', '.join(x) if isinstance(x, list) else None)\n",
    "\n",
    "    interventions_manual_review['temp'] = \"temp\"\n",
    "    interventions_manual_review.set_index([\"intervention_type\", \"orig_int\", \"description\", 'curie_info'], inplace=True)\n",
    "    interventions_manual_review.drop([\"temp\"], axis = 1, inplace = True)\n",
    "    interventions_manual_review['manually_selected_CURIE'] = None\n",
    "\n",
    "    interventions_manual_review.to_excel('{}_interventions_manual_review.xlsx'.format(relevant_date), engine='xlsxwriter', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd031435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930e56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e9602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed7a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279aa7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213d679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca767f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ec933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca117c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e11ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d033364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47173a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2399892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c91774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202e581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d2172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b512307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ETL(subset_size):\n",
    "    \n",
    "    start_time_begin = time.time()\n",
    "    flag_and_path = get_raw_ct_data() # download raw data\n",
    "    end_time_download = time.time()\n",
    "    elapsed_time = end_time_download - start_time_begin\n",
    "    hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "    print(f\"Approximate runtime for downloading or locating raw data: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "    \n",
    "    global metamap_dirs\n",
    "    metamap_dirs = check_os()\n",
    "    df_dict = read_raw_ct_data(flag_and_path, subset_size) # read the clinical trial data\n",
    "    \n",
    "    # term_list_to_cache()\n",
    "    \n",
    "    start_time_mm = time.time()\n",
    "    term_list_to_mm(df_dict, flag_and_path) # map using MetaMap\n",
    "    end_time_mm = time.time()\n",
    "    elapsed_time = end_time_mm - start_time_mm\n",
    "    hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "    print(f\"Approximate runtime for mapping: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "    \n",
    "    map_to_trial(df_dict, flag_and_path) # map MetaMap terms back to trial \n",
    "    score_mappings(flag_and_path) # score the mappings\n",
    "    auto_select_curies(flag_and_path) # select CURIEs automatically that pass score threshold\n",
    "    end_time_end = time.time()\n",
    "    elapsed_time = end_time_end - start_time_begin\n",
    "    hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "    print(f\"Approximate runtime for overall mapping: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af03e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_or_prod():\n",
    "    print(\"The test run of this code performs the construction of the KG on a random subset of 200 Conditions, 200 Interventions, and 200 Alternate Interventions from Clinical Trials.\\n\")\n",
    "    test_or_prod = input(\"Is this a test run or the production of a new version of the KG? Enter Test for test, or Prod for production: \")\n",
    "    if test_or_prod == \"Test\":\n",
    "        subset_size = 300\n",
    "        run_ETL(subset_size)\n",
    "    elif test_or_prod == \"Prod\":\n",
    "        subset_size = None\n",
    "        run_ETL(subset_size)\n",
    "    else:\n",
    "        print(\"Bad input\")\n",
    "        sys.exit(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05525299-5c4c-47cb-a5af-26cbc4c04fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "block out placebo etc\n",
    "retrieve/create cache\n",
    "track progress of creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c5078bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test run of this code performs the construction of the KG on a random subset of 200 Conditions, 200 Interventions, and 200 Alternate Interventions from Clinical Trials.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this a test run or the production of a new version of the KG? Enter Test for test, or Prod for production:  Test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting download of Clinical Trial data as of 12_15_2023\n",
      "Failed to scrape AACT for download. Please navigate to https://aact.ctti-clinicaltrials.org/download and manually download zip file.\n",
      "Please store the downloaded zip in the /data directory\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type Done when done:  Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at: \n",
      "/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/9opmph4n5l7055moqnfu3n6kxnc0.zip\n",
      "Please make sure this the correct zip file from AACT\n",
      "Unzipping data into\n",
      "/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/12_11_2023_extracted\n",
      "Approximate runtime for downloading or locating raw data: 0.0 hours, 1.0 minutes, 14.143150091171265 seconds\n",
      "MetaMap version < 2020, conduct mapping on terms after removing ascii characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% conditions mapped: 100%|| 280/280 [03:12<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using UMLS MetaMap to get mappings for INTERVENTIONS. MetaMap returns mappings, CUIs, and semantic type of mapping.\n",
      "MetaMap version < 2020, conduct mapping on original interventions after removing ascii characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% interventions mapped: 100%|| 293/293 [03:26<00:00,  1.42it/s]\n",
      "% alternate_interventions mapped: 100%|| 293/293 [03:26<00:00,  1.42i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate runtime for mapping: 0.0 hours, 10.0 minutes, 7.185937881469727 seconds\n",
      "Mapping UMLS CURIEs and names back to clinical trials\n",
      "Scoring mappings\n",
      "Auto-selecting high scoring CURIEs\n",
      "Approximate runtime for overall mapping: 0.0 hours, 11.0 minutes, 27.955234050750732 seconds\n"
     ]
    }
   ],
   "source": [
    "test_or_prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef9367-fb9a-4285-968b-7a38a81bd309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time_begin = time.time()\n",
    "# flag_and_path = get_raw_ct_data() # download raw data\n",
    "# end_time_download = time.time()\n",
    "# elapsed_time = end_time_download - start_time_begin\n",
    "# hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "# print(f\"Approximate runtime for downloading or locating raw data: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "# flag_and_path = get_raw_ct_data() # download raw data\n",
    "\n",
    "\n",
    "flag_and_path = {'term_program_flag': False,\n",
    "                 # 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/09_26_2023_extracted',\n",
    "                 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/12_11_2023_extracted',\n",
    "                 'date_string':'12_11_2023'} # comment for production\n",
    "subset_size = 20\n",
    "\n",
    "global metamap_dirs\n",
    "metamap_dirs = check_os()\n",
    "df_dict = read_raw_ct_data(flag_and_path, subset_size) # read the clinical trial data\n",
    "\n",
    "# term_list_to_cache()\n",
    "\n",
    "start_time_mm = time.time()\n",
    "term_list_to_mm(df_dict, flag_and_path) # map using MetaMap\n",
    "end_time_mm = time.time()\n",
    "elapsed_time = end_time_mm - start_time_mm\n",
    "hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "print(f\"Approximate runtime for mapping: {hours} hours, {minutes} minutes, {seconds} seconds\")\n",
    "\n",
    "map_to_trial(df_dict, flag_and_path) # map MetaMap terms back to trial \n",
    "score_mappings(flag_and_path) # score the mappings\n",
    "auto_select_curies(flag_and_path) # select CURIEs automatically that pass score threshold\n",
    "end_time_end = time.time()\n",
    "elapsed_time = end_time_end - start_time_begin\n",
    "hours, minutes, seconds = convert_seconds_to_hms(elapsed_time)\n",
    "print(f\"Approximate runtime for overall mapping: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9946bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_ETL_mapping(flag_and_path):\n",
    "#     df_dict = read_raw_ct_data(flag_and_path)\n",
    "#     ct_terms = exact_match_mesh(df_dict)\n",
    "#     ct_terms = inexact_match_mesh(df_dict, ct_terms)\n",
    "\n",
    "#     # pull the available MeSH terms per study out of the returned ct_terms dict \n",
    "#     mesh_conditions_per_study = ct_terms[\"mesh_conditions_per_study\"]\n",
    "#     mesh_interventions_per_study = ct_terms[\"mesh_interventions_per_study\"]\n",
    "\n",
    "#     ct_terms = term_list_to_nr(df_dict, ct_terms)\n",
    "#     ct_terms = term_list_to_mm(df_dict, ct_terms)\n",
    "\n",
    "#     # pull the available UMLS terms per study out of the returned ct_terms dict \n",
    "#     all_metamapped_conditions = ct_terms[\"all_metamapped_conditions\"]\n",
    "#     all_metamapped_interventions = ct_terms[\"all_metamapped_interventions\"]\n",
    "\n",
    "#     remaining_unmapped_possible = {\"mesh_conditions_per_study\": mesh_conditions_per_study,\n",
    "#                                    \"mesh_interventions_per_study\": mesh_interventions_per_study,\n",
    "#                                    \"all_metamapped_conditions\": all_metamapped_conditions,\n",
    "#                                    \"all_metamapped_interventions\": all_metamapped_interventions}\n",
    "#     compile_and_output(df_dict, ct_terms, remaining_unmapped_possible)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(interventions_manual_review[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f144ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8b9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5607f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e73280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408b038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f341e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1da2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15b6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514e180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d75b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flag_and_path = get_raw_ct_data() # uncomment for production\n",
    "flag_and_path = {'term_program_flag': False,\n",
    "                 # 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/09_26_2023_extracted',\n",
    "                 'data_extracted_path': '/Users/Kamileh/Work/ISB/NCATS_BiomedicalTranslator/Projects/ClinicalTrials/ETL_Python/data/9opmph4n5l7055moqnfu3n6kxnc0.zip',\n",
    "\n",
    "                 'date_string':'12_11_2023'} # comment for production\n",
    "metamap_dirs = check_os()\n",
    "df_dict = read_raw_ct_data(flag_and_path, subset_size=100)\n",
    "# term_list_to_mm(df_dict, flag_and_path)\n",
    "# map_to_trial(df_dict, flag_and_path)\n",
    "# score_mappings(flag_and_path)\n",
    "# auto_select_curies(flag_and_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_stats(df_dict, flag_and_path):\n",
    "    \"\"\" Report counts of conditions, interventions\"\"\"\n",
    "    relevant_date = flag_and_path[\"date_string\"] # get date\n",
    "    \n",
    "    total_conditions = df_dict[\"conditions\"].downcase_name\n",
    "    total_conditions = list(total_conditions.unique())\n",
    "    total_conditions = list(filter(None, total_conditions))\n",
    "    \n",
    "    orig_interventions = df_dict[\"interventions\"]\n",
    "    orig_interventions = orig_interventions['name'].str.lower()\n",
    "    orig_interventions = list(orig_interventions.unique())\n",
    "    orig_interventions = list(filter(None, orig_interventions))\n",
    "    \n",
    "    alt_interventions = df_dict[\"interventions_alts\"].alt_downcase_name\n",
    "    alt_interventions = list(alt_interventions.unique())\n",
    "    alt_interventions = list(filter(None, alt_interventions))\n",
    "    \n",
    "#     metamap_input = \"{}_metamap_output.tsv\".format(relevant_date)\n",
    "    \n",
    "#     \"\"\" Get the full names of the semantic types and replace the abbreviations with the full names \"\"\"\n",
    "#     metamapped = pd.read_csv(metamap_input, sep='\\t', index_col=False, header=0)\n",
    "\n",
    "    print(\"Clinical Trial Data from: {}\".format(relevant_date))\n",
    "    print(\"Total # of unique conditions : {}\".format(len(total_conditions)))\n",
    "    print(\"Total # of unique interventions : {}\".format(len(orig_interventions) + len(alt_interventions)))\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
